{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST digit classification using TensorFlow 2.0"
      ],
      "metadata": {
        "id": "t5S6b8rjdHU8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z7ugZLvjWq2C"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist"
      ],
      "metadata": {
        "id": "L9TqSSRqXH_N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = tf.cast(x_train/255.0, tf.float32), tf.cast(x_test/255.0, tf.float32)\n",
        "y_train, y_test = tf.cast(y_train,tf.int64),tf.cast(y_test,tf.int64)"
      ],
      "metadata": {
        "id": "JUV2u6jOXJEE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's define our model as a Sequential() model, as follows\n",
        "model = Sequential()\n",
        "# In a sequential model, we stack each layer, one above another"
      ],
      "metadata": {
        "id": "3HVDOSuDW_z0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = tf.keras.Input(shape=(28, 28, 1))\n",
        "layer1 = Dense(256, activation='relu')(Flatten()(input))\n",
        "# We defined layer1, but where is the input to layer1 coming from? We need to specify the input to layer1 in a bracket notation at the end\n",
        "layer2 = Dense(128, activation='relu')(layer1)\n",
        "output = Dense(10, activation='softmax')(layer2)\n",
        "model = tf.keras.Model(inputs=input, outputs=output)"
      ],
      "metadata": {
        "id": "8CaRZcQrXEkY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Now that we have defined the model, the next step is to compile it. In this phase, we set up how the model should learn. We define three parameters when compiling the model:\n",
        "\n",
        "The optimizer parameter: This defines the optimization algorithm we want to use; for example, the gradient descent, in this case.\n",
        "The loss parameter: This is the objective function that we are trying to minimize; for example, the mean squared error or cross-entropy loss.\n",
        "The metrics parameter: This is the metric through which we want to assess the model's performance; for example, accuracy. We can also specify more than one metric.\n",
        "\"\"\"\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# If labels are integers → Use sparse_categorical_crossentropy (No need to convert labels).\n",
        "# If labels are one-hot encoded → Use categorical_crossentropy. [1, 0, 0], [0, 1, 0], [0, 0, 1]"
      ],
      "metadata": {
        "id": "zVBA-ZTDXGJB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model can be done using the fit function. We specify our features, x; labels, y; the number of epochs we want to train; and the batch_size\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgc3-eeyXNCt",
        "outputId": "4faed750-e0f8-4069-cd5d-f313b13e6974"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7231 - loss: 1.0164\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9177 - loss: 0.2942\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.2400\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9420 - loss: 0.2026\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1790\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9559 - loss: 0.1584\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 0.1442\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1279\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.1148\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9715 - loss: 0.1070\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fbe4de6b6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyOxV-anXPs3",
        "outputId": "ac583a41-1582-4805-b9ee-de29e90db7ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9611 - loss: 0.1318\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1137709692120552, 0.9664999842643738]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}